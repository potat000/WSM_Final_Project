from typing import List, Dict, Union 
from database import ChromaDBManager
import chromadb
# # æ¨¡æ“¬å‘é‡
# DUMMY_VECTOR = [0.123, 0.456, 0.789] 

# zh_texts = ["ä¸­æ–‡ Chunk A: é€™æ˜¯ Google çš„æœ€æ–°æŠ€è¡“ã€‚", "ä¸­æ–‡ Chunk B: TSMC çš„å ±å‘ŠæŒ‡å‡ºæ•ˆèƒ½æå‡ã€‚"]
# zh_embeddings = [DUMMY_VECTOR, DUMMY_VECTOR]
# zh_metadatas = [{"company_name": "Google"}, {"company_name": "TSMC"}]
# zh_ids = ["zh_001", "zh_002"]

# en_texts = ["English Chunk A: Microsoft released a patch.", "English Chunk B: Apple's M4 chip is fast."]
# en_embeddings = [DUMMY_VECTOR, DUMMY_VECTOR]
# en_metadatas = [{"company_name": "Microsoft"}, {"company_name": "Apple"}]
# en_ids = ["en_003", "en_004"]


# # ----------------------------------------------------
# # ä½¿ç”¨ ChromaDBManager é¡åˆ¥
# # ----------------------------------------------------

# # 1. åˆå§‹åŒ– Managerï¼ŒåŒæ™‚å‰µå»ºå…©å€‹ Collection
# manager = ChromaDBManager(
#     persist_directory="./my_db",
#     collection_names=['docs_zh', 'docs_en'] # åœ¨åˆå§‹åŒ–æ™‚å‰µå»º
# )

# # 2. å­˜å„²ä¸­æ–‡æ•¸æ“š
# manager.save_chunks_to_chroma(
#     collection_name="docs_zh",
#     texts=zh_texts,
#     #embeddings=zh_embeddings,
#     metadatas=zh_metadatas,
#     ids=zh_ids
# )

# # 3. å­˜å„²è‹±æ–‡æ•¸æ“š
# manager.save_chunks_to_chroma(
#     collection_name="docs_en",
#     texts=en_texts,
#     #embeddings=en_embeddings,
#     metadatas=en_metadatas,
#     ids=en_ids
# )

# # 4. (å¯é¸) é©—è­‰å­˜å„²çµæœ
# zh_col = manager.get_collection("documents_zh")
# if zh_col:
#     count = zh_col.count()
#     print(f"\né©—è­‰çµæœ: docs_zh ä¸­å…±æœ‰ {count} æ¢æ•¸æ“šã€‚")

# ###  é€²è¡Œæª¢ç´¢
# # 1. åŸ·è¡Œä¸­æ–‡æª¢ç´¢ï¼Œä¸å¸¶éæ¿¾æ¢ä»¶
# query_zh_no_filter = "äººå·¥æ™ºæ…§çš„æœ€æ–°ç™¼å±•"
# results1 = manager.query_chunks(
#     collection_name="docs_zh",
#     query_text=query_zh_no_filter,
#     top_k=2
# )
# print(results1)
# # è¼¸å‡ºçµæœ (results1 æ˜¯ä¸€å€‹å­—å…¸ï¼Œæ‚¨é€šå¸¸æœƒä½¿ç”¨ results1['documents'][0] ä¾†ç²å–æ–‡æœ¬å…§å®¹)

# # 2. åŸ·è¡Œä¸­æ–‡æª¢ç´¢ï¼Œå¸¶æœ‰å…¬å¸éæ¿¾æ¢ä»¶
# query_zh_with_filter = "å ±å‘Šæœ€æ–°é€²åº¦"
# results2 = manager.query_chunks(
#     collection_name="docs_zh",
#     query_text=query_zh_with_filter,
#     top_k=3,
#     where_filter={"company_name": {"$eq": "TSMC"}} # åªåœ¨ TSMC çš„æ–‡æª”ä¸­é€²è¡Œæœç´¢
# )
# # 3. åŸ·è¡Œè‹±æ–‡æª¢ç´¢
# query_en = "security patch release"
# results3 = manager.query_chunks(
#     collection_name="docs_en",
#     query_text=query_en,
#     top_k=1,
#     where_filter={"company_name": {"$eq": "Microsoft"}} # åªåœ¨ Microsoft çš„æ–‡æª”ä¸­é€²è¡Œæœç´¢
# )

if __name__ == "__main__":
    db_path = "./my_vector_db"
    client = chromadb.PersistentClient(path=db_path)

    def audit_collection(collection_name, expected_lang):
        print(f"\nğŸ•µï¸â€â™€ï¸ æ­£åœ¨å¯©è¨ˆ Collection: {collection_name} (é æœŸèªè¨€: {expected_lang})")
        
        try:
            coll = client.get_collection(collection_name)
        except:
            print("âŒ Collection ä¸å­˜åœ¨")
            return

        # è®€å–æ‰€æœ‰ metadata (ä¸è®€å– embedding ä»¥ç¯€çœè¨˜æ†¶é«”)
        data = coll.get(include=["metadatas", "documents"])
        
        wrong_count = 0
        total = len(data["ids"])
        
        for i in range(total):
            meta = data["metadatas"][i]
            doc = data["documents"][i]
            
            # åˆ¤æ–·ä¾æ“š 1: æª¢æŸ¥ Metadata (å¦‚æœä½ çš„åŸå§‹è³‡æ–™æœ‰ language æ¬„ä½)
            if meta and "language" in meta:
                if meta["language"] != expected_lang:
                    wrong_count += 1
                    if wrong_count <= 3: # åªå°å‡ºå‰å¹¾å€‹éŒ¯èª¤ç¯„ä¾‹
                        print(f"  âš ï¸ ç™¼ç¾éŒ¯èª¤ Metadata! ID: {data['ids'][i]}, Meta: {meta}")
            
            # åˆ¤æ–·ä¾æ“š 2: ç°¡å–®çš„å…§å®¹åµæ¸¬ (å‚™ç”¨æ–¹æ¡ˆ)
            # å¦‚æœé æœŸæ˜¯ä¸­æ–‡ï¼Œä½†å‰50å­—è£¡é¢è‹±æ–‡å–®å­—å¤ªå¤šï¼Œå¯èƒ½å°±æ˜¯æ··å…¥äº†
            # é€™åªæ˜¯ä¸€å€‹ç²—ç•¥çš„ heuristic
            if expected_lang == "zh":
                # ç°¡å–®æª¢æŸ¥ï¼šå¦‚æœä¸€æ®µè©±è£¡é¢è‹±æ–‡å­—å…ƒè¶…é 80% å¯èƒ½æ˜¯éŒ¯çš„
                english_char_count = sum(1 for c in doc if c.isascii())
                if len(doc) > 0 and (english_char_count / len(doc)) > 0.8:
                    print(f"  âš ï¸ å…§å®¹ç–‘ä¼¼è‹±æ–‡ (åœ¨ä¸­æ–‡åº«ä¸­): {doc[:50]}...")
                    
        if wrong_count == 0:
            print(f"âœ… æª¢æŸ¥å®Œç•¢ï¼šæ‰€æœ‰ {total} ç­†è³‡æ–™çœ‹èµ·ä¾†éƒ½ç¬¦åˆ Metadata æ¨™è¨˜ã€‚")
        else:
            print(f"âŒ è­¦å‘Šï¼šç™¼ç¾ {wrong_count} ç­†è³‡æ–™å¯èƒ½æ”¾éŒ¯ä½ç½®ï¼")

    # åŸ·è¡Œæª¢æŸ¥
    audit_collection("docs_zh", "zh")
    audit_collection("docs_en", "en")